{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "841dfc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51247fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NUSW_NB15_Dataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        ds_type = path.split('/')[-1].split('-')[0]\n",
    "        df = pd.read_csv(path)\n",
    "        \n",
    "        x = df.drop(['id', 'attack_cat', 'label'], axis=1)\n",
    "        y = df['label']\n",
    "\n",
    "        self.x = torch.Tensor(x.to_numpy())\n",
    "        self.y = torch.Tensor(y).to(dtype=torch.long)\n",
    "\n",
    "        self.dim = self.x.shape[1]\n",
    "\n",
    "        print(\n",
    "            f'Finished reading the {ds_type} set of Dataset '\\\n",
    "            f'({len(self.x)} samples found, each dim = {self.dim})'\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aad9a401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataloader(path, batch_size, shuffle):\n",
    "    dataset = NUSW_NB15_Dataset(path)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size,\n",
    "        shuffle\n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2150966a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(196, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a6e6703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    avg_loss, avg_correct = 0, 0\n",
    "    model.train()\n",
    "    with tqdm(dataloader) as pbar:\n",
    "        for (X, y) in pbar:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            # Compute prediction error\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # sum loss and correct\n",
    "            avg_loss += loss.item()\n",
    "            avg_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "            # set loss val to pbar\n",
    "            pbar.set_postfix(loss=f'{loss.item():>7f}')\n",
    "    \n",
    "    # cal avg loss and correct\n",
    "    avg_loss /= num_batches\n",
    "    avg_correct /= size\n",
    "    print(f\"[Train] Accuracy: {(100*avg_correct):>0.1f}%, Avg loss: {avg_loss:>8f} \\n\")\n",
    "    return avg_loss, avg_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e856251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"[Test] Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8a8e3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path\n",
    "tr_path = '../data/processed/training-set.csv'\n",
    "val_path = '../data/processed/validation-set.csv'\n",
    "tt_path = '../data/processed/testing-set.csv'\n",
    "log_path = '../logs/anomaly_detection'\n",
    "model_path = '../models/anomaly_detection/model_weights.pth'\n",
    "\n",
    "# hyperparameter\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fac3696e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading the training set of Dataset (164910 samples found, each dim = 196)\n",
      "Finished reading the validation set of Dataset (41228 samples found, each dim = 196)\n",
      "Finished reading the testing set of Dataset (51535 samples found, each dim = 196)\n"
     ]
    }
   ],
   "source": [
    "# prepare dataloader\n",
    "tr_dl = prep_dataloader(\n",
    "    tr_path,\n",
    "    batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dl = prep_dataloader(\n",
    "    val_path,\n",
    "    batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "tt_dl = prep_dataloader(\n",
    "    tt_path,\n",
    "    batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f880a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Load model weights form ../models/anomaly_detection/model_weights.pth\n",
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "942c733cb0ab456989ab27506f772264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2577 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Accuracy: 89.3%, Avg loss: 0.237368 \n",
      "\n",
      "[Test] Accuracy: 89.4%, Avg loss: 0.227329 \n",
      "\n",
      "Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2969a9884cc4d6fbf19b5b9bf49460d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2577 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Accuracy: 89.6%, Avg loss: 0.220199 \n",
      "\n",
      "[Test] Accuracy: 89.7%, Avg loss: 0.213946 \n",
      "\n",
      "Saving model to ../models/anomaly_detection/model_weights.pth\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# summary writer\n",
    "last_log_path = os.path.join(log_path, datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "writer = SummaryWriter(last_log_path)\n",
    "\n",
    "# neural network\n",
    "model = NeuralNetwork().to(device)\n",
    "\n",
    "# load model weight\n",
    "if os.path.isfile(model_path):\n",
    "    print(f'Load model weights form {model_path}')\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# loss func and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "# training and validation\n",
    "epochs = 2\n",
    "for t in range(epochs):\n",
    "    ep = t + 1\n",
    "    print(f\"Epoch {ep}\")\n",
    "    tr_loss, tr_acc = train(tr_dl, model, loss_fn, optimizer)\n",
    "    tt_loss, tt_acc = test(val_dl, model, loss_fn)\n",
    "    \n",
    "    # log loss and acc\n",
    "    writer.add_scalar('Loss/train', tr_loss, ep)\n",
    "    writer.add_scalar('Accuracy/train', tr_acc, ep)\n",
    "    writer.add_scalar('Loss/test', tt_loss, ep)\n",
    "    writer.add_scalar('Accuracy/test', tt_acc, ep)\n",
    "    \n",
    "print(f'Saving model to {model_path}\\n')\n",
    "torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a83ddf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Accuracy: 89.4%, Avg loss: 0.218754 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.21875412857377205, 0.8938003298729019)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "test(tt_dl, model, loss_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
